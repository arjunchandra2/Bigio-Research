Annotations are saved from the Matlab software in a .mat file with the following format:

annotations{1,3} - Class name in column 1
annotations{1,4} - RGB value of annotation box (not needed)
annotations{1,5} - z plane 
annotations{1,6} - Bounding box coordinates as [top left x, top left y, width, height]

The .mat file will need to be parsed and appropriate data should be kept for cropping

Algorithm for Cropping:

Given that annotations are likely sparse in large images, we will not use a sliding window. Instead, we crop images
around each bounding box that has not yet been covered, selecting a random position for cropping. 
We then check the other bounding boxes for overlap beyond some threshold and crop as necessary, going plane by plane in the 
z-stack. **This could be inefficient if there are a large number of bounding boxes, in which case we might consider
 sorting and only checking other bounding boxes as necessary or reverting to a sliding window**

Saving Cropped Images and Annotations:

Cropped images with annotations should be saved in a new folder in the working directory named ./results and the images will be split into
train and val folders according to yolo format:

results
   |train
        |images
        |labels
    |val
        |images
        |labels

Annotation Formats:

Yolov8 - https://docs.ultralytics.com/datasets/detect/

Each image has one txt file with a single line for each bounding box. The format of each row is:

class_id center_x center_y width height

where fields are space delimited, and the coordinates are normalized from zero to one.

Note: To convert to normalized xywh from pixel values, divide x (and width) by the image's width
and divide y (and height) by the image's height.

The `data.yaml` file contains configuration values used by the model to locate images
and map class names to class_id's.


Augmentation:
We will add an option to add augmentation when the images are cropped. Here are the augmentations that will be 
implemented:

1. 10x Random croppings 
2. 4x Orientations (no rotation, 1x rotation 90 degrees right, 2x rotation 90 degrees right, 3x rotation 90 degrees right)
3. 2x Channel Swapping: (R, G, B) and (R-1.4B, G, B) <- changing orientation of defects 

This will scale the dataset by a factor of 80x. We can consider modifying this later if augmentation is redundant
and does not improve training.

Validation set will not include augmentation and a separate image or set of images will be reserved for validation 
since defects in nearby planes are the same defect which will create similarities between the training and validation
set and yield artificially high accuracy. 


SCRIPT SPECIFIC NOTES

main.py:

- when loading .mat files strings must be stored as character arrays so that
they are not parsed as Matlab Opaque objects 
- strip whitespace from defect classes  
- there can be slight variation in # of images in each run and where annotations are
due to randomness
- modification for SCC directory setup:
data_dirs = ['/projectnb/npbssmic/ac25/RGB_Data_Anna',\
                 '/projectnb/npbssmic/ac25/RGB_Data_Arjun']

results_dir = "/projectnb/npbssmic/ac25/Dataset_Preparation/results"
for data_directory in data_dirs:   

Bbox.py:

- We need to clean up the data from the annotation software when we load it in since there are 
some bugs resulting in duplicate data and annotations from blurry planes


